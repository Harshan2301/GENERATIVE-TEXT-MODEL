{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnBhB8xkdmJ9+pIPKGlnjx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshan2301/GENERATIVE-TEXT-MODEL/blob/main/GENERATIVE_TEXT_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "\n",
        "# Initialize generator\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "set_seed(42)\n",
        "# Generate text from user prompt\n",
        "prompt = \"Artificial intelligence is transforming\"\n",
        "generated = generator(prompt, max_length=100, num_return_sequences=1)\n",
        "\n",
        "print(generated[0]['generated_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_XpTAZU2Dni",
        "outputId": "a2624e61-6bd7-4e47-91eb-4c4b76d0f591"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial intelligence is transforming into a massive, global social phenomenon. More than 50 countries have already started with AI systems, and there are a lot more to come. In 2014, IBM will be the only US company to offer a full-fledged AI system. It will be the world's biggest AI company in 2014, and will be the third-largest company by market share to date, behind HP and Google.\n",
            "\n",
            "In a statement, IBM said it will \"continue to build on our achievements to build the next generation of connected devices and applications that will transform our lives, and will enable our employees, partners, and customers to enjoy the benefits and benefits of this transformative technology\".\n",
            "\n",
            "IBM's new AI system will be based on Watson, a machine learning platform that will be integrated into the next-generation IBM AI system. Watson will be developed by IBM Research, a company that is part of the IBM AI division. IBM will be able to make further advances in its AI product development, including new design, development, and delivery technologies, and Watson will be able to make further advances in AI product development and delivery.\n",
            "\n",
            "IBM will also explore the feasibility of building the next generation of Watson IoT-enabled products. In 2015, IBM will launch IBM-Tricycle, a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6bnTJ9ie2Zsp"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}